{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c2b86b-409a-480a-84ee-ca6312caef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b9624-9a62-49a5-a0e2-955e293ad557",
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxtPath = r\"Downloads\\deploy.prototxt\"\n",
    "weightsPath = r\"Downloads\\res10_300x300_ssd_iter_140000.caffemodel\"\n",
    "faceNet = cv2.dnn.readNet(prototxtPath, weightsPath)\n",
    "labels_dict={0:'NO MASK',1:'MASK'}\n",
    "color_dict={0:(0,0,255),1:(0,255,0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9c8490-b0ea-4a06-8051-761e9e424cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)\n",
    "data_without=[]\n",
    "while True:\n",
    "  flag,img=capture.read()\n",
    "  if flag:\n",
    "    h, w = img.shape[:2]\n",
    "      \n",
    "    # Preprocess the frame: resize, normalize, and create a blob\n",
    "    blob = cv2.dnn.blobFromImage(img, 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "    faceNet.setInput(blob)\n",
    "\n",
    "    # Perform face detection\n",
    "    detections = faceNet.forward()\n",
    "\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # Filter detections with confidence > 0.5\n",
    "        if confidence > 0.5:\n",
    "            # Get bounding box coordinates\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # Draw a rectangle around the detected face\n",
    "            cv2.rectangle(img, (startX, startY), (endX, endY), (255, 0, 255), 4)\n",
    "\n",
    "            # Extract and preprocess the face region\n",
    "            face = img[startY:endY, startX:endX]\n",
    "            face = cv2.resize(face, (100, 100))\n",
    "            data_without.append(face)\n",
    "            \n",
    "            print(f\"Captured faces: {len(data_without)}\")\n",
    "\n",
    "\n",
    "    cv2.imshow('OUTPUT',img)\n",
    "    if cv2.waitKey(1) == 27 or len(data_without)>=400:\n",
    "      break\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363613f-b39b-40ad-b67f-598b5155ad94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "for i in range(len(data_without)):\n",
    "    mpimg.imsave(f\"dataset/without_mask/{i}.png\", data_without[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
